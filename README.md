# LAX Data Analysis Project
This repository contains a comprehensive data analysis project focusing on Los Angeles International Airport (LAX) data. Three separate datasets were extracted from Data.gov related to LAX cargo, flight operations, and terminal passenger traffic.

### Data Sets
- Cargo: Los Angeles International Airport Air Cargo Volume
  https://catalog.data.gov/dataset/los-angeles-international-airport-air-cargo-volume
  
- Flight Ops: Los Angeles International Airport Flight Operations by Month
  https://catalog.data.gov/dataset/los-angeles-international-airport-flight-operations-by-month
  
- Terminal: Los Angeles International Airport Passenger Traffic by Terminal
  https://catalog.data.gov/dataset/los-angeles-international-airport-passenger-traffic-by-terminal
  
### Tools Used
- Jupyter Notebook
- Python libraries: Pandas, seaborn, matplotlib
- SQLAlchemy (for database connection)
- PostgreSQL (for database storage and querying)
  
### Project Overview
The LAX Data Analysis Project involved several key steps:

### Data Preprocessing
- Data Cleaning: Removed inconsistencies, errors, and irrelevant information from the datasets to ensure data integrity.
- Data Exploration: Utilized Pandas for initial data exploration to understand the structure and contents of the datasets.
  
### Database Setup
- Database Creation: Used SQLAlchemy to connect to PostgreSQL and create a database.
- Data Loading: Stored the three datasets in PostgreSQL tables using Python and SQL Alchemy.
  
### Data Analysis
- Statistical Analysis: Conducted statistical analysis to derive insights and identify patterns in the datasets.
- Exploratory Analysis: Utilized PostgreSQL to perform exploratory analysis using SQL queries on the database.
  
### Data Visualization
- Visualization Creation: Utilized seaborn and matplotlib to create visualizations such as charts, graphs, and plots to represent the findings from the analysis.
  
### Repository Structure
- Data: Contains the original dataset files downloaded from Data.gov.
- Notebooks: Includes Jupyter Notebook files showcasing the data cleaning, exploratory analysis, and visualization process.
- Database: Contains scripts and documentation related to database creation and data loading.
- Visualizations: Houses visualizations generated using seaborn and matplotlib.
  
### How to Use
- Clone this repository to your local machine.
- Explore the data files in the Data directory.
- Review the Jupyter Notebook files in the Notebooks directory for data preprocessing, exploratory analysis, and visualization.
- Check the Database directory for scripts and documentation related to database setup and querying.
  
### Contributors
Isagani Julian Hernandez
